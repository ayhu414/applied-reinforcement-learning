{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cb46d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from gym.envs.classic_control import CartPoleEnv\n",
    "from rlutils import Agent, enact_policy, evaluate_agent, state_cols\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d3c1b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Actions/State\n",
    "\n",
    "\n",
    "        | (0,0) | U/1|  (2,0) |\n",
    "        |L/4    | X  | R/2    |\n",
    "        | (0,2) | D/3| (2,2)  |\n",
    "\"\"\" \n",
    "\n",
    "\n",
    "class BPFEnv():\n",
    "    def __init__(self, n_residues_max, residues):\n",
    "        assert len(residues) <= n_residues_max, \"Invalid Protein\"\n",
    "        # self.hyperparameters = ? may need some here\n",
    "        residues_ = []\n",
    "        for i in range(len(residues)):\n",
    "            if(i < len(residues)):\n",
    "                residues_ += [residues[i]]\n",
    "            else:\n",
    "                residues_ += [0]\n",
    "        self.state = np.array(([0]*(n_residues_max*2 + 1)**2) + residues_ + [n_residues_max, n_residues_max])\n",
    "        self.n_residues_max = n_residues_max\n",
    "        # flat representation of the state\n",
    "    def make_state_pretty(self):\n",
    "        #convert the flat representation of the state into something more easily useable\n",
    "        nrm = self.n_residues_max\n",
    "        grid = self.state[:(2*nrm+1)**2].reshape(2*nrm+1, 2*nrm+1)\n",
    "        residues = self.state[(2*nrm+1)**2:(2*nrm+1)**2+nrm]\n",
    "        pos = [self.state[-2], self.state[-1]]\n",
    "        return (grid, residues, pos)\n",
    "    def state_from_pretty(self, pretty):\n",
    "        grid = pretty[0]\n",
    "        residues = pretty[1]\n",
    "        pos = pretty[2]\n",
    "        state_ = np.concatenate([grid.flatten(), residues], axis=0)\n",
    "        state_ = np.concatenate([state_, pos], axis=0)\n",
    "        self.state = state_\n",
    "        \n",
    "    def increment(self, action):\n",
    "        # double check the move makes sense\n",
    "        assert action in [1,2,3,4], \"Action \" +str(action) + \" is invalid\"\n",
    "        \n",
    "        state_prime = self.make_state_pretty()\n",
    "        board = state_prime[0]\n",
    "        residues = state_prime[1]\n",
    "        position = state_prime[2]\n",
    "        \n",
    "        position[0] += (action % 2 ==0) * (np.sign(3-action)) # i.e. if the action is divisible by 2 (right or left) with appropriate sign\n",
    "        position[1] += (not action%2 == 0) * (np.sign(action-2)) # these lines just move where our cursor is\n",
    "        board[position[0],position[1]] = residues[0] # change board at cursor to leading residues\n",
    "        residues = [residues[i] for i in range(1, len(residues))] + [0] # remove first residue\n",
    "        self.state = np.concatenate([board.flatten(), residues, position], axis=0)\n",
    "        \n",
    "    def reset(self):\n",
    "        return self.state, {}\n",
    "    def compute_energy(self, state):\n",
    "        # first attempt at the energy functional\n",
    "        side_of_board_reward = 0\n",
    "        energy = 0\n",
    "        board = state[0]\n",
    "        for i in range(len(board)):\n",
    "            for j in range(len(board[i])):\n",
    "                ep = 0\n",
    "                if(j < len(board[i])-1):\n",
    "                    ep += np.abs(board[i][j+1]+board[i][j])\n",
    "                else:\n",
    "                    ep += side_of_board_reward\n",
    "                if(j > 0):\n",
    "                    ep += np.abs(board[i][j-1]+board[i][j])\n",
    "                else:\n",
    "                    ep += side_of_board_reward\n",
    "                if(i > 0):\n",
    "                    ep += np.abs(board[i-1][j] + board[i][j])\n",
    "                else:\n",
    "                    ep += side_of_board_reward\n",
    "                if(i < len(board[j]-1)):\n",
    "                    ep += np.abs(board[i+1][j] + board[i][j])\n",
    "                else:\n",
    "                    ep += side_of_board_reward\n",
    "                # if any of the residues match, they are awarded 2 points. If they are blank, they are awarded 1pt\n",
    "                # if they are different they are awarded 0 points. We then\n",
    "                energy += ep\n",
    "                    \n",
    "    def step(self, action):\n",
    "        assert action in [1,2,3,4], \"Action \" +str(action) + \" is invalid\"\n",
    "        \n",
    "        reward = 0\n",
    "        new_state = self.increment(action)\n",
    "        \n",
    "        #now we need to implement the rewards\n",
    "        \n",
    "        #SELF - AVOIDING\n",
    "        if(not np.count_nonzero(new_state[0]) > np.count_nonzero(state[0])):\n",
    "            # this means the action overlapped with a previous residue\n",
    "            reward += 0.01\n",
    "            done = True\n",
    "        if(len(self.state[2]) == 0):\n",
    "            reward += 0.5\n",
    "            done = True #finished protein\n",
    "        #ENERGY \n",
    "        if(not done):\n",
    "            reward += self.compute_energy(new_state)\n",
    "        \n",
    "        \n",
    "        return new_state, reward, done, {}\n",
    "\n",
    "    def show(self):\n",
    "        # display a picture of the current state\n",
    "        state_ = self.make_state_pretty()\n",
    "        x = state_[0]\n",
    "        green = [[i,j] for i in range(len(x)) for j in range(len(x[i])) if x[i][j] == -1]\n",
    "        blue =  [[i,j] for i in range(len(x)) for j in range(len(x[i])) if x[i][j] == 1]\n",
    "        green = np.array(green)\n",
    "        blue = np.array(blue)\n",
    "        plt.scatter(green[:,0],green[:,1],color=\"green\", lw=5)\n",
    "        plt.scatter(blue[:, 0], blue[:, 1],color=\"teal\", lw=5)\n",
    "        plt.xlim(0,self.n_residues_max*2 +1)\n",
    "        plt.ylim(0,self.n_residues_max*2 +1)\n",
    "        plt.grid()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "296d64e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = BPFEnv(10, [-1,1,-1,1,1,-1,-1,-1,1,1])\n",
    "env.increment(2)\n",
    "env.increment(1)\n",
    "env.increment(4)\n",
    "env.increment(2)\n",
    "env.increment(1)\n",
    "env.increment(4)\n",
    "env.increment(2)\n",
    "env.increment(1)\n",
    "env.increment(4)\n",
    "env.increment(1)\n",
    "env.increment(4)\n",
    "env.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19feab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent(Agent):\n",
    "    \"\"\"An agent trained using DQN\"\"\"\n",
    "    \n",
    "    def __init__(self, gamma=0.9, epsilon=0.75, epsilon_decay=0.01, epsilon_min=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            gamma: Discount rate for future rewards\n",
    "            epsilon: Exploration value\n",
    "            epsilon_decay: How much we decay the rewards after each update\n",
    "        \"\"\"\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min\n",
    "        \n",
    "        # Make a model that predicts the value of a move and actions\n",
    "        self.q_function = self.make_q_function()\n",
    "        self.q_function.compile(loss='mse', optimizer='adam')\n",
    "        \n",
    "        # Memory for all observed moves\n",
    "        self.memory = pd.DataFrame()\n",
    "        self.max_memory = 2048\n",
    "        \n",
    "    def make_q_function(self):\n",
    "        \"\"\"Generate a Q-function that computes the value of both actions given state\"\"\"\n",
    "        return Sequential([\n",
    "            Dense(128, activation='relu', input_shape=(22,)),\n",
    "            Dense(64, activation='relu', input_shape=(4,)),\n",
    "            Dense(2, activation='linear')\n",
    "        ])\n",
    "    \n",
    "    def get_action(self, state):       \n",
    "        if np.random.random() < self.epsilon:\n",
    "            # Choose action randomly\n",
    "            return np.random.randint(1,5)\n",
    "        else:\n",
    "            # Compute the value of each move\n",
    "            q_values = self.q_function.predict(state[np.newaxis, :])[0]\n",
    "            \n",
    "            # Pick the best value\n",
    "            return np.argmax(q_values)\n",
    "    \n",
    "    def train(self, states):\n",
    "        # Compute the next state for each state\n",
    "        #  Numpy roll rotates the array from [1, ... N] to [2, ... N, 1]\n",
    "        next_state_cols = []  # Stores the columns in the DataFrame that involve refitting the \n",
    "        for c in state_cols:\n",
    "            next_state_cols.append(f'next_{c}')\n",
    "            states[f'next_{c}'] = np.roll(states[c], -1)\n",
    "        \n",
    "        # Add new states to the memory\n",
    "        self.memory = pd.concat([self.memory, states])\n",
    "        \n",
    "        # If needed, sample fewer points from the memory to keep it from becoming too big\n",
    "        if len(self.memory) > self.max_memory:\n",
    "            self.memory = self.memory.sample(self.max_memory)\n",
    "        \n",
    "        # Get compute the Q value for the next state\n",
    "        #  The value is zero for the last point because there is no next state\n",
    "        q_value_next = np.max(self.q_function.predict(self.memory[next_state_cols].values), axis=1)\n",
    "        q_value_next = np.where(self.memory['done'], 0, q_value_next)\n",
    "        \n",
    "        # Compute the target Q-values\n",
    "        q_target = self.memory['reward'].values + self.gamma * q_value_next\n",
    "        \n",
    "        # Save the old weights\n",
    "        self.q_function.fit(self.memory[state_cols].values, q_target, shuffle=True, batch_size=32, verbose=False)\n",
    "        \n",
    "        # Last step, make the algorithm more greedy\n",
    "        self.epsilon *= (1 - self.epsilon_decay)\n",
    "        self.epsilon = max(self.epsilon, self.epsilon_min)\n",
    "        return \n",
    "agent = DQNAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4400ec81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95614f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = BPFEnv(4, [-1,1,-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d8946c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
